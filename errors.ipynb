{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def _init_(self,\n",
    "                 input_chanel: list,\n",
    "                 channel_sizes: list,\n",
    "                 kernel_sizes: list,\n",
    "                 \n",
    "                 ann_layer_sizes: list,\n",
    "                 dropout: float\n",
    "                 ) -> None:\n",
    "        \n",
    "        self.input_channel: int = input_chanel\n",
    "        self.channel_sizes: list = channel_sizes\n",
    "        self.kernel_sizes: list  = kernel_sizes\n",
    "\n",
    "        self.ann_layer_sizes: list = ann_layer_sizes\n",
    "        self.dropout: float = dropout \n",
    "\n",
    "        super()._init_()\n",
    "        \n",
    "        # you may define your model in here but i prefer to define it in the forward function\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(self.input_channel, self.channel_sizes[0], self.kernel_sizes[0], padding= \"same\"), # 6-256-256 -> 16-256-256\n",
    "            #nn.Conv2d(self.channel_sizes[0], self.channel_sizes[0], self.kernel_sizes[0], padding= \"same\"), # 16-256-256 -> 16-256-256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.MaxPool2d(kernel_size= 2, stride= 2), # 16-256-256 -> 16-128-128\n",
    "\n",
    "            nn.Conv2d(self.channel_sizes[0], self.channel_sizes[1], self.kernel_sizes[1], padding= \"same\"), # 16-128-128 -> 32-128-128\n",
    "            #nn.Conv2d(self.channel_sizes[1], self.channel_sizes[1], self.kernel_sizes[1], padding= \"same\"), # 32-128-128 -> 32-128-128\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.MaxPool2d(kernel_size= 2, stride= 2), # 32-128-128 - 32-64-64\n",
    "\n",
    "            nn.Conv2d(self.channel_sizes[1], self.channel_sizes[2], self.kernel_sizes[2], padding= \"same\"), # 32-64-64 -> 64-64-64\n",
    "            #nn.Conv2d(self.channel_sizes[2], self.channel_sizes[2], self.kernel_sizes[2], padding= \"same\"), # 64-64-64 -> 64-64-64\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.MaxPool2d(kernel_size= 2, stride= 2), # 64-64-64 -> 64-32-32\n",
    "            \n",
    "            nn.Conv2d(self.channel_sizes[2], self.channel_sizes[3], self.kernel_sizes[3], padding= \"same\"), # 64-32-32 -> 128-32-32\n",
    "            #nn.Conv2d(self.channel_sizes[3], self.channel_sizes[3], self.kernel_sizes[3], padding= \"same\"), # 128-32-32 -> 128-32-32\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.MaxPool2d(kernel_size= 2, stride= 2), # 128-32-32 -> 128-16-16\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(self.ann_layer_sizes[0], self.ann_layer_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.ann_layer_sizes[1], self.ann_layer_sizes[2]),    \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.ann_layer_sizes[2], self.ann_layer_sizes[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.ann_layer_sizes[3], 1),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        ) # ??? \n",
    "    \n",
    "    def forward(self, real_image, generated_image):\n",
    "        x = torch.cat([real_image, generated_image], 2)\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size: int, instance_shape: list, discriminator, generator, generator_optimizer, criterion, label_image):\n",
    "\n",
    "    generator_optimizer.zero_grad()\n",
    "\n",
    "    noise = torch.randn(batch_size, instance_shape[0], instance_shape[1]).to(device)\n",
    "    \n",
    "    altered_image = generator(noise, label_image)\n",
    "\n",
    "    validity = discriminator.forward(altered_image, label_image) # ?? constructor of discriminator is wrong if you want to get result you should use your forward function\n",
    "    \n",
    "\n",
    "    #torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')[SOURCE]\n",
    "    #Creates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\n",
    "    g_loss = criterion(validity, torch.ones(batch_size).to(device)) \n",
    "    \n",
    "    \n",
    "    g_loss.backward()\n",
    "\n",
    "    generator_optimizer.step()\n",
    "\n",
    "    return g_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    print(\"Starting epoch {}...\".format(epoch + 1))\n",
    "\n",
    "    for red_apples, green_apples in zip(red_data_loader, green_data_loader):\n",
    "        \n",
    "        red_apples = red_apples.to(device) \n",
    "        green_apples = green_apples.to(device)\n",
    "\n",
    "        generator.train()\n",
    "        # you encountiring the Attribute Error because you are passing instance to BCE which is not a tensor \n",
    "        # you should pass the output of the discriminator to the BCE loss function\n",
    "        d_loss = discriminator_train_step(batch_size, discriminator,\n",
    "                                          generator, discriminator_optimizer,\n",
    "                                          criterion, red_apples, green_apples, (256, 256))\n",
    "        \n",
    "        g_loss = generator_train_step(batch_size, (256, 256), discriminator, \n",
    "                                      generator, generator_optimizer, criterion)\n",
    "    \n",
    "    generator.eval()\n",
    "\n",
    "    print(\"generator loss: {}, discriminator loss: {}\".format(g_loss, d_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
